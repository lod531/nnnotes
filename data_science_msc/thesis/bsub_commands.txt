TEXT=examples/language_model/wikitext-2-raw_1000
fairseq-preprocess \
    --only-source \
    --trainpref $TEXT/wiki.train.raw \
    --validpref $TEXT/wiki.valid.raw \
    --testpref $TEXT/wiki.test.raw \
    --destdir data-bin/wikitext-2-raw_1000 \
    --workers 20


######################################################################################################
######################################################################################################
kneser :

bsub -J w2_n2_kneser_0.01 -W 1200 -o runs/w2_n2_kneser_0.01.txt -R "rusage[ngpus_excl_p=1,mem=50000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2_n2_kneser_0.01 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion kneser_ney_smoothing --kneser-d 0.01 --kneser-n 2 \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

-W 1200 -o runs/w2_n2_kneser_0.8.txt  -R "select[gpu_mtotal0>=15240]"

-o runs/wikitext2_4000_kneser_d0.1_n3.txt
######################################################################################################
######################################################################################################
cross entropy

bsub -J w2_cross_entropy -o runs/w2_cross_entropy.txt -W 1200 -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2_cross_entropy \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion cross_entropy \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 500000

######################################################################################################
######################################################################################################

Label smoothing:
bsub -J w_2_label_smoothing_0.1 -W 1200 -o runs/w2_label_smoothing_0.1.txt -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2_label_smoothing_0.1 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion label_smoothed_cross_entropy --label-smoothing 0.1 \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

######################################################################################################
######################################################################################################
Good turing:

bsub -J w2_good_turing_n1 -o runs/w2_good_turing_n1.txt -W 1200 -R "rusage[ngpus_excl_p=1,mem=20000]"  CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2_good_turing_n1 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion good_turing_smoothing --good-turing-n 1 \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

runs/wikitext2_n1_good_turing.txt

bsub -J good_turing -I  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2 \
--save-dir /cluster/scratch/andriusb/checkpoints/wikitext2_good_turing_test \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion good_turing_smoothing --good-turing-n 2 \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 20 \
--max-update 50000

-o runs/wikitext2_good_turing_n3.txt
-J good_turing 
-R "select[gpu_mtotal0>=12240]"


######################################################################################################
######################################################################################################
Katz

bsub -J w2_katz_k5_n2 -o runs/w2_katz_k5_n2.txt -W 1200 -R "rusage[ngpus_excl_p=1,mem=20000]" -R "select[gpu_mtotal0>=12240]"  CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2_katz_k5_n2 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion katz_smoothing --katz-k 5 --katz-n 2 \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000


bsub -J katz -I -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-4000 \
--save-dir /cluster/scratch/andriusb/checkpoints/transformer_wikitext-2-katz_test \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion katz_smoothing --katz-k 3 --katz-n 3 \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 20 \
--max-update 50000

######################################################################################################
######################################################################################################
Jelinek

bsub -J w2_jelinek_0.05_0.95 -W 1200 -o runs/w2_jelinek_0.05_0.95.txt  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.95 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion jelinek_mercer_smoothing  --jelinek-n 2 --alphas '(0.05, 0.95)' \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

bsub -J w2_jelinek_0.1_0.9 -W 1200 -o runs/w2_jelinek_0.1_0.9.txt  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.9 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion jelinek_mercer_smoothing  --jelinek-n 2 --alphas '(0.1, 0.9)' \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

bsub -J w2_jelinek_0.15_0.85 -W 1200 -o runs/w2_jelinek_0.15_0.85.txt  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek0.15_0.85 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion jelinek_mercer_smoothing  --jelinek-n 2 --alphas '(0.15, 0.85)' \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

bsub -J w2_jelinek_0.2_0.8 -W 1200 -o runs/w2_jelinek_0.2_0.8.txt  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.2_0.8 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion jelinek_mercer_smoothing  --jelinek-n 2 --alphas '(0.2, 0.8)' \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000

bsub -J w2_jelinek_0.25_0.75 -W 1200 -o runs/w2_jelinek_0.25_0.75.txt  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-train --task language_modeling \
data-bin/wikitext-2-raw-full \
--save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.25_0.75 \
--arch transformer_lm --share-decoder-input-output-embed \
--dropout 0.5 \
--criterion jelinek_mercer_smoothing  --jelinek-n 2 --alphas '(0.25, 0.75)' \
--optimizer adam --adam-betas '(0.9, 0.98)' --weight-decay 0.5 --clip-norm 0.0 \
--lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \
--tokens-per-sample 512 --sample-break-mode none \
--max-tokens 2048 --update-freq 16 \
--save-interval 40 \
--max-update 50000



EVALUATION

bsub -I  -R "rusage[ngpus_excl_p=1,mem=20000]" CUDA_VISIBLE_DEVICES=0  \
fairseq-eval-lm data-bin/wikitext-2-raw-full \
--path /cluster/scratch/andriusb/checkpoints/w2_label_smoothing_0.1/checkpoint_best.pt \
--max-sentences 2 \
--tokens-per-sample 512 \
--context-window 510


w2_cross_entropy      w2-jelinek_0.1_0.9    w2_katz_k2_n2  w2_label_smoothing_0.001  w2_label_smoothing_0.06  w2_n2_kneser_0.02  w2_n2_kneser_0.32
w2_good_turing_n1     w2-jelinek0.15_0.85   w2_katz_k3_n2  w2_label_smoothing_0.01   w2_label_smoothing_0.08  w2_n2_kneser_0.04  w2_n2_kneser_0.64
w2_good_turing_n2     w2-jelinek_0.2_0.8    w2_katz_k4_n2  w2_label_smoothing_0.02   w2_label_smoothing_0.1   w2_n2_kneser_0.08
w2-jelinek_0.05_0.95  w2-jelinek_0.25_0.75  w2_katz_k5_n2  w2_label_smoothing_0.04   w2_n2_kneser_0.01        w2_n2_kneser_0.16
