\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@ifundefined{amsrefs@bibcite}{}{\let\bibcite\amsrefs@bibcite}
\bibstyle{amsrn}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Regularizing Neural Networks by Penalizing Confident Output Distributions}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Aight}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Smoothing as KL penalty}{5}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}KL and entropy penalty}{7}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Jurafsky and Martin - Speech and Language Processing}{9}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}N-Grams}{9}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Laplace Smoothing}{9}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Good-Turing Smoothing}{10}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}On the Estimation of 'Small' Probabilities by Leaving-One-Out}{11}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Good-Turing Smooth Stanford Lecture}{14}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Good Turing Let Me Go}{15}{subsubsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6}Okay so here is a Good-Turing Smoothing derivation}{16}{subsubsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7}One Last Good Time, I Swear}{18}{subsubsection.2.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8}Issues in Good-Turing}{18}{subsubsection.2.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.9}Backoff and Interpolation}{19}{subsubsection.2.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.10}Katz Backoff}{19}{subsubsection.2.1.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Working through what's already there}{20}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Jelinek-Mercer}{21}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}So now what}{22}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}From count to log likelihood}{22}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Additive Smoothing}{23}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Mistakes}{27}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Deriving it I suppose}{29}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{33}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Entropy}{33}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Cross Entropy}{33}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}KL Divergence}{33}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Perplexity}{34}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}As a measure of model confusion}{34}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Lagrange Multipliers}{34}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Unigram MLE}{35}{subsection.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Bigram MLE}{37}{subsection.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Unigram MLE with Uniform distribution KL}{38}{subsection.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.9.1}Sanity Check}{40}{subsubsection.5.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10}Unigram MLE with Uniform distribution KL but right lol}{43}{subsection.5.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.10.1}Mistakes}{46}{subsubsection.5.10.1}\protected@file@percent }
